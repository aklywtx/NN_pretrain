
torch.Size([64, 3, 256, 256]) torch.Size([64])
Epochs:   0%|                                                                                                                                  | 0/50 [00:00<?, ?it/s]
























































































































































































































































































































































































































































































































































































































































































Traceback (most recent call last):
  File "/Users/aklywtx/Desktop/VLM_Bias_research/NN_pretrain/models/vit_train.py", line 108, in <module>
    main()
  File "/Users/aklywtx/Desktop/VLM_Bias_research/NN_pretrain/models/vit_train.py", line 102, in main
    trainer.train(train_loader, val_loader, num_epochs)
  File "/Users/aklywtx/Desktop/VLM_Bias_research/NN_pretrain/models/utils.py", line 126, in train
    self.optimizer.step()
  File "/Users/aklywtx/opt/anaconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py", line 75, in wrapper
    return wrapped(*args, **kwargs)
  File "/Users/aklywtx/opt/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py", line 391, in wrapper
    out = func(*args, **kwargs)
  File "/Users/aklywtx/opt/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/Users/aklywtx/opt/anaconda3/lib/python3.9/site-packages/torch/optim/adamw.py", line 188, in step
    adamw(
  File "/Users/aklywtx/opt/anaconda3/lib/python3.9/site-packages/torch/optim/adamw.py", line 340, in adamw
    func(
  File "/Users/aklywtx/opt/anaconda3/lib/python3.9/site-packages/torch/optim/adamw.py", line 473, in _single_tensor_adamw
    param.addcdiv_(exp_avg, denom, value=-step_size)
KeyboardInterrupt